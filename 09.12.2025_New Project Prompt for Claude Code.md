I need to create a new Python project for web scraping startup job listings from 15+ job board websites. This is a fresh project (not modifying existing code) that will scrape job data, process it, and generate reports.

**Project Requirements:**
- Web scraping system targeting startup job boards (AngelList, Y Combinator, etc.)
- Async Python architecture with proper rate limiting and anti-detection measures
- Modular design with separate scrapers for each site
- Data processing pipeline for job filtering and normalization
- Database storage and caching system
- Professional reporting (markdown/HTML output)
- Configuration management for different sites
- Error handling and monitoring

**Key Considerations:**
- Respect robots.txt and implement reasonable rate limits
- Handle dynamic content and JavaScript-heavy sites
- Implement user agent rotation and request throttling
- Focus on startup-specific job filtering
- Design for scalability (15+ sites)
- Maintain clean, maintainable code architecture

**Deliverables Needed:**
- Project structure and file organization
- Base scraper class and example implementations
- Configuration system for site-specific settings
- Database schema for job storage
- Basic data processing and reporting framework
- Requirements.txt with necessary dependencies
- Virtual environment setup instructions

Please create the initial project foundation with a clear structure, core components, and example code that I can build upon. Focus on the architecture and core patterns rather than implementing all 15 scrapers initially.

---

